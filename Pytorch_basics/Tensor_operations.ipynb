{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cc8ccd2",
   "metadata": {},
   "source": [
    "# Tensor Operations\n",
    "This section covers:\n",
    "* Indexing and slicing\n",
    "* Reshaping tensors (tensor views)\n",
    "* Tensor arithmetic and basic operations\n",
    "* Dot products\n",
    "* Matrix multiplication\n",
    "* Additional, more advanced operations\n",
    "\n",
    "## Perform standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "095c7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea853d9",
   "metadata": {},
   "source": [
    "## Indexing and slicing\n",
    "Extracting specific values from a tensor works just the same as with NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1e81eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(6).reshape(3,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1abfc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e0c9fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "597060b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3],\n",
       "        [5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bcdb32",
   "metadata": {},
   "source": [
    "## Reshape tensors with <tt>.view()</tt>\n",
    "<a href='https://pytorch.org/docs/master/tensors.html#torch.Tensor.view'><strong><tt>view()</tt></strong></a> and <a href='https://pytorch.org/docs/master/torch.html#torch.reshape'><strong><tt>reshape()</tt></strong></a> do essentially the same thing by returning a reshaped tensor without changing the original tensor in place.<br>\n",
    "There's a good discussion of the differences <a href='https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch'>here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdde7a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd286a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "print(x.view(2,5))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ff7685f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "print(x.reshape(2,5))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac99df9",
   "metadata": {},
   "source": [
    "### Views reflect the most current data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89300702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x arr:\n",
      "tensor([9999,    1,    2,    3,    4,    5,    6,    7,    8,    9])\n",
      "z arr:\n",
      "tensor([[9999,    1,    2,    3,    4],\n",
      "        [   5,    6,    7,    8,    9]])\n"
     ]
    }
   ],
   "source": [
    "z = x.view(2,5)\n",
    "x[0] = 9999\n",
    "print(f'x arr:\\n{x}')\n",
    "print(f'z arr:\\n{z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19151664",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a2435",
   "metadata": {},
   "source": [
    "### Views can infer the correct size\n",
    "By passing in <tt>-1</tt> PyTorch will infer the correct value from the given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "201bc7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INFER what the 2nd dimension\n",
    "x.view(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c92ea15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13933dab",
   "metadata": {},
   "source": [
    "## Tensor Arithmetic\n",
    "Adding tensors can be performed a few different ways depending on the desired result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec7250c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "297047ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 5., 6.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.Tensor([4,5,6])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f70326f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 9.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0a08f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 7., 9.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73d012c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after a.mul :\n",
      "tensor([ 4., 10., 18.])\n",
      "after a.mul_:\n",
      "tensor([ 16.,  50., 108.])\n"
     ]
    }
   ],
   "source": [
    "# a * b\n",
    "a.mul(b)\n",
    "print(f'after a.mul :\\n{a}') # a stay the same\n",
    "# a = a * b\n",
    "a.mul_(b)\n",
    "print(f'after a.mul_:\\n{a}') # a get reasign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b8d53",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> Any operation that changes a tensor in-place is post-fixed with an underscore _.\n",
    "    <br>In the above example: <tt>a.add_(b)</tt> changed <tt>a</tt>.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8655c653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da5f4ad",
   "metadata": {},
   "source": [
    "## Dot products\n",
    "A <a href='https://en.wikipedia.org/wiki/Dot_product'>dot product</a> is the sum of the products of the corresponding entries of two 1D tensors. If the tensors are both vectors, the dot product is given as:<br>\n",
    "\n",
    "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d & e & f \\end{bmatrix} = ad + be + cf$\n",
    "\n",
    "If the tensors include a column vector, then the dot product is the sum of the result of the multiplied matrices. For example:<br>\n",
    "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d \\\\ e \\\\ f \\end{bmatrix} = ad + be + cf$<br><br>\n",
    "Dot products can be expressed as <a href='https://pytorch.org/docs/stable/torch.html#torch.dot'><strong><tt>torch.dot(a,b)</tt></strong></a> or `a.dot(b)` or `b.dot(a)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "964b82e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dot(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9994921",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> There's a slight difference between <tt>torch.dot()</tt> and <tt>numpy.dot()</tt>. While <tt>torch.dot()</tt> only accepts 1D arguments and returns a dot product, <tt>numpy.dot()</tt> also accepts 2D arguments and performs matrix multiplication. We show matrix multiplication below.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fc6a6c",
   "metadata": {},
   "source": [
    "## Matrix multiplication\n",
    "2D <a href='https://en.wikipedia.org/wiki/Matrix_multiplication'>Matrix multiplication</a> is possible when the number of columns in tensor <strong><tt>A</tt></strong> matches the number of rows in tensor <strong><tt>B</tt></strong>. In this case, the product of tensor <strong><tt>A</tt></strong> with size $(x,y)$ and tensor <strong><tt>B</tt></strong> with size $(y,z)$ results in a tensor of size $(x,z)$\n",
    "<div>\n",
    "\n",
    "$\\begin{bmatrix} a & b & c \\\\\n",
    "d & e & f \\end{bmatrix} \\;\\times\\; \\begin{bmatrix} m & n \\\\ p & q \\\\ r & s \\end{bmatrix} = \\begin{bmatrix} (am+bp+cr) & (an+bq+cs) \\\\\n",
    "(dm+ep+fr) & (dn+eq+fs) \\end{bmatrix}$</div></div>\n",
    "Matrix multiplication can be computed using <a href='https://pytorch.org/docs/stable/torch.html#torch.mm'><strong><tt>torch.mm(a,b)</tt></strong></a> or `a.mm(b)` or `a @ b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10b3dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "b: tensor([[ 7.,  8.],\n",
      "        [ 9., 10.],\n",
      "        [11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "b = torch.Tensor([[7,8],[9,10],[11,12]])\n",
    "\n",
    "print(f'a: {a}')\n",
    "print(f'b: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03ad8fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 58.,  64.],\n",
       "        [139., 154.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa1824",
   "metadata": {},
   "source": [
    "### Matrix multiplication with broadcasting\n",
    "Matrix multiplication that involves <a href='https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics'>broadcasting</a> can be computed using <a href='https://pytorch.org/docs/stable/torch.html#torch.matmul'><strong><tt>torch.matmul(a,b)</tt></strong></a> or `a.matmul(b)` or `a @ b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c056b6f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m t1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      2\u001b[0m t2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m torch\u001b[38;5;241m.\u001b[39mmm(t1,t2)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "t1 = torch.randn(2,4,4)\n",
    "t2 = torch.randn(4,5)\n",
    "\n",
    "torch.mm(t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9733b995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.1431,  2.8203, -2.0512, -3.2533, -4.3642],\n",
       "         [ 3.4309,  1.1813, -3.9589, -1.3524, -0.5890],\n",
       "         [-0.4506,  0.9921,  1.6111,  1.7922,  1.0522],\n",
       "         [ 1.5785,  0.2698,  0.7073,  0.3044, -1.7832]],\n",
       "\n",
       "        [[-0.5113,  0.3929, -1.0074, -1.1493,  0.9895],\n",
       "         [-4.0703,  0.1589,  2.6202,  0.3666,  2.7941],\n",
       "         [ 1.9066, -2.4961, -2.0511,  2.0448, -1.6237],\n",
       "         [ 2.2026, -1.3199, -2.5710,  1.1377, -1.0649]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.randn(2, 4, 4)\n",
    "t2 = torch.randn(4, 5)\n",
    "\n",
    "torch.matmul(t1,t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7ba0fe",
   "metadata": {},
   "source": [
    "___\n",
    "# Advanced operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75acc166",
   "metadata": {},
   "source": [
    "## L2 or Euclidian Norm\n",
    "See <a href='https://pytorch.org/docs/stable/torch.html#torch.norm'><strong><tt>torch.norm()</tt></strong></a>\n",
    "\n",
    "The <a href='https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm'>Euclidian Norm</a> gives the vector norm of $x$ where $x=(x_1,x_2,...,x_n)$.<br>\n",
    "It is calculated as<br>\n",
    "\n",
    "${\\displaystyle \\left\\|{\\boldsymbol {x}}\\right\\|_{2}:={\\sqrt {x_{1}^{2}+\\cdots +x_{n}^{2}}}}$\n",
    "\n",
    "\n",
    "When applied to a matrix, <tt>torch.norm()</tt> returns the <a href='https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm'>Frobenius norm</a> by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5649fa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.7473)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([4,8,3,7])\n",
    "\n",
    "x.norm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b8f148",
   "metadata": {},
   "source": [
    "## Number of elements\n",
    "See <a href='https://pytorch.org/docs/stable/torch.html#torch.numel'><strong><tt>torch.numel()</tt></strong></a>\n",
    "\n",
    "Returns the number of elements in a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e362f7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3,7)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c93fbb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
